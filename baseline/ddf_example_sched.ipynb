{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10d35822-897d-4d47-836b-359cefd38f93",
   "metadata": {},
   "source": [
    "Mostly coppied from https://github.com/lsst/rubin_scheduler/blob/main/rubin_scheduler/scheduler/surveys/ddf_presched.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "447192ed-d929-443d-93b1-b299f739c8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "\n",
    "from rubin_scheduler.data import get_data_dir\n",
    "from rubin_scheduler.scheduler.utils import scheduled_observation\n",
    "from rubin_scheduler.utils import calc_season, ddf_locations, survey_start_mjd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9ecdace-e321-4ae3-b1c8-374c077f73a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data file containing handy depths over time for each DDF location\n",
    "data_file = os.path.join(get_data_dir(), \"scheduler\", \"ddf_grid.npz\")\n",
    "ddf_data = np.load(data_file)\n",
    "ddf_grid = ddf_data[\"ddf_grid\"].copy()\n",
    "ddf_data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28784b14-f3aa-4914-9782-a7c80c5c6682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype([('mjd', '<f8'), ('sun_alt', '<f8'), ('sun_n18_rising_next', '<f8'), ('ELAISS1_airmass', '<f8'), ('ELAISS1_sky_g', '<f8'), ('ELAISS1_m5_g', '<f8'), ('XMM_LSS_airmass', '<f8'), ('XMM_LSS_sky_g', '<f8'), ('XMM_LSS_m5_g', '<f8'), ('ECDFS_airmass', '<f8'), ('ECDFS_sky_g', '<f8'), ('ECDFS_m5_g', '<f8'), ('COSMOS_airmass', '<f8'), ('COSMOS_sky_g', '<f8'), ('COSMOS_m5_g', '<f8'), ('EDFS_a_airmass', '<f8'), ('EDFS_a_sky_g', '<f8'), ('EDFS_a_m5_g', '<f8'), ('EDFS_b_airmass', '<f8'), ('EDFS_b_sky_g', '<f8'), ('EDFS_b_m5_g', '<f8')])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can see the grid has MJD, and then airmass, sky brightness, amd g-band 5-sigma limiting depth per ddf\n",
    "# Note the depth is assuming some nominal constant seeing (probably 0.7 arcsec at zenith)\n",
    "ddf_grid.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a495f99-54e3-4308-8f04-1c32e19b4130",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_ddf_times(\n",
    "    ddf_name,\n",
    "    ddf_RA,\n",
    "    ddf_grid,\n",
    "    sun_limit=-18,\n",
    "    sequence_time=60.0,\n",
    "    airmass_limit=2.5,\n",
    "    sky_limit=None,\n",
    "    g_depth_limit=23.5,\n",
    "    season_unobs_frac=0.1,\n",
    "):\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ddf : `str`\n",
    "        The name of the DDF\n",
    "    ddf_grid : `np.array`\n",
    "        An array with info for the DDFs. Generated by the\n",
    "        rubin_scheduler.scheduler/surveys/generate_ddf_grid.py` script\n",
    "    season_unobs_frac : `float`\n",
    "        7.2 month observing season if season_unobs_frac = 0.2 (shaves 20% off\n",
    "        each end of the full year)\n",
    "    sequence_time : `float`\n",
    "        How long a sequence is expected to be (minutes). Used to make\n",
    "        sure things are not scheduled too close to twilight.\n",
    "    \"\"\"\n",
    "    sun_limit = np.radians(sun_limit)\n",
    "    sequence_time = sequence_time / 60.0 / 24.0  # to days\n",
    "\n",
    "    # XXX-- double check that I got this right\n",
    "    ack = ddf_grid[\"sun_alt\"][0:-1] * ddf_grid[\"sun_alt\"][1:]\n",
    "    night = np.zeros(ddf_grid.size, dtype=int)\n",
    "    night[np.where((ddf_grid[\"sun_alt\"][1:] >= 0) & (ack < 0))] += 1\n",
    "    night = np.cumsum(night)\n",
    "    ngrid = ddf_grid[\"mjd\"].size\n",
    "\n",
    "    # set a sun, airmass, sky masks\n",
    "    sun_mask = np.ones(ngrid, dtype=int)\n",
    "    sun_mask[np.where(ddf_grid[\"sun_alt\"] >= sun_limit)] = 0\n",
    "\n",
    "    # expand sun mask backwards by the sequence time.\n",
    "    n_back = np.ceil(sequence_time / (ddf_grid[\"mjd\"][1] - ddf_grid[\"mjd\"][0])).astype(int)\n",
    "    shadow_indx = np.where(sun_mask == 0)[0] - n_back\n",
    "    shadow_indx = shadow_indx[np.where(shadow_indx >= 0)]\n",
    "\n",
    "    sun_mask[shadow_indx] = 0\n",
    "\n",
    "    airmass_mask = np.ones(ngrid, dtype=int)\n",
    "    airmass_mask[np.where(ddf_grid[\"%s_airmass\" % ddf_name] >= airmass_limit)] = 0\n",
    "\n",
    "    sky_mask = np.ones(ngrid, dtype=int)\n",
    "    if sky_limit is not None:\n",
    "        sky_mask[np.where(ddf_grid[\"%s_sky_g\" % ddf_name] <= sky_limit)] = 0\n",
    "        sky_mask[np.where(np.isnan(ddf_grid[\"%s_sky_g\" % ddf_name]) == True)] = 0\n",
    "\n",
    "    m5_mask = np.zeros(ngrid, dtype=bool)\n",
    "    m5_mask[np.isfinite(ddf_grid[\"%s_m5_g\" % ddf_name])] = 1\n",
    "\n",
    "    if g_depth_limit is not None:\n",
    "        m5_mask[np.where(ddf_grid[\"%s_m5_g\" % ddf_name] < g_depth_limit)] = 0\n",
    "\n",
    "    big_mask = sun_mask * airmass_mask * sky_mask * m5_mask\n",
    "\n",
    "    potential_nights = np.unique(night[np.where(big_mask > 0)])\n",
    "\n",
    "    # prevent a repeat sequence in a night\n",
    "    unights, indx = np.unique(night, return_index=True)\n",
    "    night_mjd = ddf_grid[\"mjd\"][indx]\n",
    "    # The season of each night\n",
    "    night_season = calc_season(ddf_RA, night_mjd)\n",
    "\n",
    "    raw_obs = np.ones(unights.size)\n",
    "    # take out the ones that are out of season\n",
    "    season_mod = night_season % 1\n",
    "\n",
    "    out_season = np.where((season_mod < season_unobs_frac) | (season_mod > (1.0 - season_unobs_frac)))\n",
    "    raw_obs[out_season] = 0\n",
    "\n",
    "    cumulative_desired = ddf_slopes(ddf_name, raw_obs, night_season)\n",
    "\n",
    "    night_mask = unights * 0\n",
    "    night_mask[potential_nights] = 1\n",
    "\n",
    "    unight_sched = match_cumulative(cumulative_desired, mask=night_mask)\n",
    "    cumulative_sched = np.cumsum(unight_sched)\n",
    "\n",
    "    nights_to_use = unights[np.where(unight_sched == 1)]\n",
    "\n",
    "    # For each night, find the best time in the night.\n",
    "    # XXX--probably need to expand this part to resolve the times when multiple things get scheduled\n",
    "    mjds = []\n",
    "    for night_check in nights_to_use:\n",
    "        in_night = np.where((night == night_check) & (np.isfinite(ddf_grid[\"%s_m5_g\" % ddf_name])))[0]\n",
    "        m5s = ddf_grid[\"%s_m5_g\" % ddf_name][in_night]\n",
    "        # we could intorpolate this to get even better than 15 min resolution on when to observe\n",
    "        max_indx = np.where(m5s == m5s.max())[0].min()\n",
    "        mjds.append(ddf_grid[\"mjd\"][in_night[max_indx]])\n",
    "\n",
    "    return mjds, night_mjd, cumulative_desired, cumulative_sched\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4385d0d2-8dad-4244-939c-f5782148e578",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ddf_slopes(ddf_name, raw_obs, night_season):\n",
    "    \"\"\"\n",
    "    Let's make custom slopes for each DDF\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ddf_name : str\n",
    "       The DDF name to use\n",
    "    raw_obs : np.array\n",
    "        An array with values of 1 or zero. One element per night, value of\n",
    "        1 indicates the night is during an active observing season.\n",
    "    night_season : np.array\n",
    "        An array of floats with the fractional season value\n",
    "        (e.g., 0.5 would be half way through the first season)\n",
    "    \"\"\"\n",
    "\n",
    "    # OK, so 258 sequences is ~1% of the survey\n",
    "    # so a 25.8 sequences is a 0.1% season\n",
    "    # COSMOS is going to be 0.7% for 3 years, then 0.175 for the rest.\n",
    "\n",
    "    ss = 30  # standard season, was 45\n",
    "\n",
    "    if (ddf_name == \"ELAISS1\") | (ddf_name == \"XMM_LSS\") | (ddf_name == \"ECDFS\"):\n",
    "        # Dict with keys for each season and values of the number of sequences\n",
    "        # to attempt.\n",
    "        season_vals = {\n",
    "            0: 10,\n",
    "            1: ss,\n",
    "            2: ss,\n",
    "            3: ss,\n",
    "            4: ss,\n",
    "            5: ss,\n",
    "            6: ss,\n",
    "            7: ss,\n",
    "            8: ss,\n",
    "            9: ss,\n",
    "            10: 10,\n",
    "        }\n",
    "\n",
    "        round_season = np.floor(night_season)\n",
    "\n",
    "        cumulative_desired = np.zeros(raw_obs.size, dtype=float)\n",
    "        for season in np.unique(round_season):\n",
    "            in_season = np.where(round_season == season)\n",
    "            cumulative = np.cumsum(raw_obs[in_season])\n",
    "            if cumulative.max() > 0:\n",
    "                cumulative = cumulative / cumulative.max() * season_vals[season]\n",
    "                cumulative_desired[in_season] = cumulative + np.max(cumulative_desired)\n",
    "\n",
    "    if ddf_name == \"EDFS_a\":\n",
    "        season_vals = {\n",
    "            0: 10,\n",
    "            1: ss,\n",
    "            2: ss,\n",
    "            3: ss,\n",
    "            4: ss,\n",
    "            5: ss,\n",
    "            6: ss,\n",
    "            7: ss,\n",
    "            8: ss,\n",
    "            9: ss,\n",
    "            10: 10,\n",
    "        }\n",
    "\n",
    "        round_season = np.floor(night_season)\n",
    "\n",
    "        cumulative_desired = np.zeros(raw_obs.size, dtype=float)\n",
    "        for season in np.unique(round_season):\n",
    "            in_season = np.where(round_season == season)\n",
    "            cumulative = np.cumsum(raw_obs[in_season])\n",
    "            if cumulative.max() > 0:\n",
    "                cumulative = cumulative / cumulative.max() * season_vals[season]\n",
    "                cumulative_desired[in_season] = cumulative + np.max(cumulative_desired)\n",
    "\n",
    "    if ddf_name == \"COSMOS\":\n",
    "        # looks like COSMOS has no in-season time for 10 at the current start mjd.\n",
    "        season_vals = {\n",
    "            0: 10,\n",
    "            1: ss * 5,\n",
    "            2: ss * 5,\n",
    "            3: ss * 2,\n",
    "            4: ss,\n",
    "            5: ss,\n",
    "            6: ss,\n",
    "            7: ss,\n",
    "            8: ss,\n",
    "            9: ss,\n",
    "            10: 10,\n",
    "        }\n",
    "\n",
    "        round_season = np.floor(night_season)\n",
    "\n",
    "        cumulative_desired = np.zeros(raw_obs.size, dtype=float)\n",
    "        for season in np.unique(round_season):\n",
    "            in_season = np.where(round_season == season)[0]\n",
    "            cumulative = np.cumsum(raw_obs[in_season])\n",
    "            if cumulative.max() > 0:\n",
    "                cumulative = cumulative / cumulative.max() * season_vals[season]\n",
    "                cumulative_desired[in_season] = cumulative + np.max(cumulative_desired)\n",
    "\n",
    "    return cumulative_desired\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6878f7a5-ec68-4c0b-8efc-bc534f2db9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_cumulative(cumulative_desired, mask=None, no_duplicate=True):\n",
    "    \"\"\"Generate a schedule that tries to match the desired cumulative distribution given a mask\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cumulative_desired : `np.array`, float\n",
    "        An array with the cumulative number of desired observations. Elements\n",
    "        are assumed to be evenly spaced.\n",
    "    mask : `np.array`, bool or int (None)\n",
    "        Set to zero for indices that cannot be scheduled\n",
    "    no_duplicate : `bool` (True)\n",
    "        If True, only 1 event can be scheduled per element\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    schedule : `np.array`\n",
    "        The resulting schedule, with values marking number of events in that cell.\n",
    "    \"\"\"\n",
    "\n",
    "    rounded_desired = np.round(cumulative_desired)\n",
    "    sched = cumulative_desired * 0\n",
    "    if mask is None:\n",
    "        mask = np.ones(sched.size)\n",
    "\n",
    "    valid = np.where(mask > 0)[0].tolist()\n",
    "    x = np.arange(sched.size)\n",
    "\n",
    "    drd = np.diff(rounded_desired)\n",
    "    step_points = np.where(drd > 0)[0] + 1\n",
    "\n",
    "    # would be nice to eliminate this loop, but it's not too bad.\n",
    "    # can't just use searchsorted on the whole array, because then there\n",
    "    # can be duplicate values, and array[[n,n]] = 1 means that extra match gets lost.\n",
    "    for indx in step_points:\n",
    "        left = np.searchsorted(x[valid], indx)\n",
    "        right = np.searchsorted(x[valid], indx, side=\"right\")\n",
    "        d1 = indx - left\n",
    "        d2 = right - indx\n",
    "        if d1 < d2:\n",
    "            sched_at = left\n",
    "        else:\n",
    "            sched_at = right\n",
    "\n",
    "        # If we are off the end\n",
    "        if sched_at >= len(valid):\n",
    "            sched_at -= 1\n",
    "\n",
    "        sched[valid[sched_at]] += 1\n",
    "        if no_duplicate:\n",
    "            valid.pop(sched_at)\n",
    "\n",
    "    return sched\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "809c5f53-6c29-4db2-89a0-fe8c9218b11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ddf_scheduled_obs(\n",
    "    data_file=None,\n",
    "    flush_length=2,\n",
    "    mjd_tol=15,\n",
    "    expt=30.0,\n",
    "    alt_min=25,\n",
    "    alt_max=85,\n",
    "    HA_min=21.0,\n",
    "    HA_max=3.0,\n",
    "    sun_alt_max=-18,\n",
    "    dist_tol=3.0,\n",
    "    season_unobs_frac=0.1,\n",
    "    nvis_master=[8, 10, 20, 20, 24, 18],\n",
    "    filters=\"ugrizy\",\n",
    "    nsnaps=[1, 2, 2, 2, 2, 2],\n",
    "    mjd_start=None,\n",
    "    survey_length=10.0,\n",
    "    sequence_time=60.0,\n",
    "):\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_file : `path` (None)\n",
    "        The data file to use for DDF airmass, m5, etc. Defaults to using whatever is in\n",
    "        rubin_sim_data/scheduler directory.\n",
    "    flush_length : `float` (2)\n",
    "        How long to keep a scheduled observation around before it is considered failed\n",
    "        and flushed (days).\n",
    "    mjd_tol : `float` (15)\n",
    "        How close an observation must be in time to be considered matching a scheduled\n",
    "        observation (minutes).\n",
    "    expt : `float` (30)\n",
    "        Total exposure time per visit (seconds).\n",
    "    alt_min/max : `float` (25, 85)\n",
    "        The minimum and maximum altitudes to permit observations to happen (degrees).\n",
    "    HA_min/max : `float` (21, 3)\n",
    "        The hour angle limits to permit observations to happen (hours).\n",
    "    dist_tol : `float` (3)\n",
    "        The distance tolerance for a visit to be considered matching a scheduled observation\n",
    "        (degrees).\n",
    "    season_unobs_frac : `float` (0.1)\n",
    "        What fraction of the season should the DDF be considered unobservable. Taken off both the\n",
    "        start and end of the year, so a season frac of 0.1 means 20% of the time the DDF is considered\n",
    "        unobservable, so it will be in-season for 9.6 months.\n",
    "    nvis_master : list of ints ([8, 10, 20, 20, 24, 18])\n",
    "        The number of visits to make per filter\n",
    "    filters : `str` (ugrizy)\n",
    "        The filter names.\n",
    "    nsnaps : `list of ints` ([1, 2, 2, 2, 2, 2])\n",
    "        The number of snaps to use per filter\n",
    "    mjd_start : `float`\n",
    "        Starting MJD of the survey. Default None, which calls rubin_sim.utils.survey_start_mjd\n",
    "    survey_length : `float`\n",
    "        Length of survey (years). Default 10.\n",
    "    \"\"\"\n",
    "    if data_file is None:\n",
    "        data_file = os.path.join(get_data_dir(), \"scheduler\", \"ddf_grid.npz\")\n",
    "\n",
    "    if mjd_start is None:\n",
    "        mjd_start = survey_start_mjd()\n",
    "\n",
    "    flush_length = flush_length  # days\n",
    "    mjd_tol = mjd_tol / 60 / 24.0  # minutes to days\n",
    "    expt = expt\n",
    "    alt_min = np.radians(alt_min)\n",
    "    alt_max = np.radians(alt_max)\n",
    "    dist_tol = np.radians(dist_tol)\n",
    "    sun_alt_max = np.radians(sun_alt_max)\n",
    "\n",
    "    ddfs = ddf_locations()\n",
    "    ddf_data = np.load(data_file)\n",
    "    ddf_grid = ddf_data[\"ddf_grid\"].copy()\n",
    "\n",
    "    mjd_max = mjd_start + survey_length * 365.25\n",
    "\n",
    "    # check if our pre-computed grid is over the time range we think we are scheduling for\n",
    "    if (ddf_grid[\"mjd\"].min() > mjd_start) | (ddf_grid[\"mjd\"].max() < mjd_max):\n",
    "        warnings.warn(\"Pre-computed DDF properties don't match requested survey times\")\n",
    "\n",
    "    in_range = np.where((ddf_grid[\"mjd\"] >= mjd_start) & (ddf_grid[\"mjd\"] <= mjd_max))\n",
    "    ddf_grid = ddf_grid[in_range]\n",
    "\n",
    "    all_scheduled_obs = []\n",
    "    for ddf_name in [\"ELAISS1\", \"XMM_LSS\", \"ECDFS\", \"COSMOS\", \"EDFS_a\"]:\n",
    "        print(\"Optimizing %s\" % ddf_name)\n",
    "\n",
    "        # 'ID', 'RA', 'dec', 'mjd', 'flush_by_mjd', 'exptime', 'filter', 'rotSkyPos', 'nexp',\n",
    "        #         'note'\n",
    "        # 'mjd_tol', 'dist_tol', 'alt_min', 'alt_max', 'HA_max', 'HA_min', 'observed'\n",
    "        mjds = optimize_ddf_times(\n",
    "            ddf_name,\n",
    "            ddfs[ddf_name][0],\n",
    "            ddf_grid,\n",
    "            season_unobs_frac=season_unobs_frac,\n",
    "            sequence_time=sequence_time,\n",
    "        )[0]\n",
    "        for mjd in mjds:\n",
    "            for filtername, nvis, nexp in zip(filters, nvis_master, nsnaps):\n",
    "                if \"EDFS\" in ddf_name:\n",
    "                    obs = scheduled_observation(n=int(nvis / 2))\n",
    "                    obs[\"RA\"] = np.radians(ddfs[ddf_name][0])\n",
    "                    obs[\"dec\"] = np.radians(ddfs[ddf_name][1])\n",
    "                    obs[\"mjd\"] = mjd\n",
    "                    obs[\"flush_by_mjd\"] = mjd + flush_length\n",
    "                    obs[\"exptime\"] = expt\n",
    "                    obs[\"filter\"] = filtername\n",
    "                    obs[\"nexp\"] = nexp\n",
    "                    obs[\"note\"] = \"DD:%s\" % ddf_name\n",
    "                    obs[\"target\"] = ddf_name\n",
    "\n",
    "                    obs[\"mjd_tol\"] = mjd_tol\n",
    "                    obs[\"dist_tol\"] = dist_tol\n",
    "                    # Need to set something for HA limits\n",
    "                    obs[\"HA_min\"] = HA_min\n",
    "                    obs[\"HA_max\"] = HA_max\n",
    "                    obs[\"alt_min\"] = alt_min\n",
    "                    obs[\"alt_max\"] = alt_max\n",
    "                    obs[\"sun_alt_max\"] = sun_alt_max\n",
    "                    all_scheduled_obs.append(obs)\n",
    "\n",
    "                    obs = scheduled_observation(n=int(nvis / 2))\n",
    "                    obs[\"RA\"] = np.radians(ddfs[ddf_name.replace(\"_a\", \"_b\")][0])\n",
    "                    obs[\"dec\"] = np.radians(ddfs[ddf_name.replace(\"_a\", \"_b\")][1])\n",
    "                    obs[\"mjd\"] = mjd\n",
    "                    obs[\"flush_by_mjd\"] = mjd + flush_length\n",
    "                    obs[\"exptime\"] = expt\n",
    "                    obs[\"filter\"] = filtername\n",
    "                    obs[\"nexp\"] = nexp\n",
    "                    obs[\"note\"] = \"DD:%s\" % ddf_name.replace(\"_a\", \"_b\")\n",
    "                    obs[\"target\"] = ddf_name.replace(\"_a\", \"_b\")\n",
    "\n",
    "                    obs[\"mjd_tol\"] = mjd_tol\n",
    "                    obs[\"dist_tol\"] = dist_tol\n",
    "                    # Need to set something for HA limits\n",
    "                    obs[\"HA_min\"] = HA_min\n",
    "                    obs[\"HA_max\"] = HA_max\n",
    "                    obs[\"alt_min\"] = alt_min\n",
    "                    obs[\"alt_max\"] = alt_max\n",
    "                    obs[\"sun_alt_max\"] = sun_alt_max\n",
    "                    all_scheduled_obs.append(obs)\n",
    "\n",
    "                else:\n",
    "                    obs = scheduled_observation(n=nvis)\n",
    "                    obs[\"RA\"] = np.radians(ddfs[ddf_name][0])\n",
    "                    obs[\"dec\"] = np.radians(ddfs[ddf_name][1])\n",
    "                    obs[\"mjd\"] = mjd\n",
    "                    obs[\"flush_by_mjd\"] = mjd + flush_length\n",
    "                    obs[\"exptime\"] = expt\n",
    "                    obs[\"filter\"] = filtername\n",
    "                    obs[\"nexp\"] = nexp\n",
    "                    obs[\"note\"] = \"DD:%s\" % ddf_name\n",
    "                    obs[\"target\"] = ddf_name\n",
    "\n",
    "                    obs[\"mjd_tol\"] = mjd_tol\n",
    "                    obs[\"dist_tol\"] = dist_tol\n",
    "                    # Need to set something for HA limits\n",
    "                    obs[\"HA_min\"] = HA_min\n",
    "                    obs[\"HA_max\"] = HA_max\n",
    "                    obs[\"alt_min\"] = alt_min\n",
    "                    obs[\"alt_max\"] = alt_max\n",
    "                    obs[\"sun_alt_max\"] = sun_alt_max\n",
    "                    all_scheduled_obs.append(obs)\n",
    "\n",
    "    result = np.concatenate(all_scheduled_obs)\n",
    "    # Put in the scripted ID so it's easier to track which ones fail.\n",
    "    result[\"scripted_id\"] = np.arange(result.size)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9506d50-ee4e-454b-9b4a-fd4197629d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing ELAISS1\n",
      "Optimizing XMM_LSS\n",
      "Optimizing ECDFS\n",
      "Optimizing COSMOS\n",
      "Optimizing EDFS_a\n"
     ]
    }
   ],
   "source": [
    "baseline_script = generate_ddf_scheduled_obs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23edb01d-0709-4b4a-9b28-59d99bce7207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(0, 0.16493361, -0.76794487, 60817.41874971, 60819.41874971, 30., 'u', 0., 0., 0., 0., 1, 'DD:ELAISS1', 'ELAISS1', 0.01041667, 0.05235988, 0.43633231, 1.48352986, 3., 21., -0.31415927, False,      0),\n",
       "       (0, 0.16493361, -0.76794487, 60817.41874971, 60819.41874971, 30., 'u', 0., 0., 0., 0., 1, 'DD:ELAISS1', 'ELAISS1', 0.01041667, 0.05235988, 0.43633231, 1.48352986, 3., 21., -0.31415927, False,      1),\n",
       "       (0, 0.16493361, -0.76794487, 60817.41874971, 60819.41874971, 30., 'u', 0., 0., 0., 0., 1, 'DD:ELAISS1', 'ELAISS1', 0.01041667, 0.05235988, 0.43633231, 1.48352986, 3., 21., -0.31415927, False,      2),\n",
       "       ...,\n",
       "       (0, 1.1100294 , -0.83077672, 64425.99166553, 64427.99166553, 30., 'y', 0., 0., 0., 0., 2, 'DD:EDFS_b', 'EDFS_b', 0.01041667, 0.05235988, 0.43633231, 1.48352986, 3., 21., -0.31415927, False, 167997),\n",
       "       (0, 1.1100294 , -0.83077672, 64425.99166553, 64427.99166553, 30., 'y', 0., 0., 0., 0., 2, 'DD:EDFS_b', 'EDFS_b', 0.01041667, 0.05235988, 0.43633231, 1.48352986, 3., 21., -0.31415927, False, 167998),\n",
       "       (0, 1.1100294 , -0.83077672, 64425.99166553, 64427.99166553, 30., 'y', 0., 0., 0., 0., 2, 'DD:EDFS_b', 'EDFS_b', 0.01041667, 0.05235988, 0.43633231, 1.48352986, 3., 21., -0.31415927, False, 167999)],\n",
       "      dtype=[('ID', '<i8'), ('RA', '<f8'), ('dec', '<f8'), ('mjd', '<f8'), ('flush_by_mjd', '<f8'), ('exptime', '<f8'), ('filter', '<U1'), ('rotSkyPos', '<f8'), ('rotTelPos', '<f8'), ('rotTelPos_backup', '<f8'), ('rotSkyPos_desired', '<f8'), ('nexp', '<i8'), ('note', '<U40'), ('target', '<U40'), ('mjd_tol', '<f8'), ('dist_tol', '<f8'), ('alt_min', '<f8'), ('alt_max', '<f8'), ('HA_max', '<f8'), ('HA_min', '<f8'), ('sun_alt_max', '<f8'), ('observed', '?'), ('scripted_id', '<i8')])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3d178a-0f87-43a3-98bc-2c0b927496f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
